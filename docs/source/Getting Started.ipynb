{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Hyperkite\n",
    "\n",
    "This short introduction uses Hyperkite to:\n",
    "\n",
    "1. Build a neural network that classifies images.\n",
    "\n",
    "2. Train the model and optimize hyperparameters.\n",
    "\n",
    "3. And finally evaluate the accuracy of the model.\n",
    "\n",
    "This tutorial is part of the original [Hyperkite Documentation](https://hyperkite.ai/docs/getting-started/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the Hyperkite package by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperkite/hyperkite.git\n",
      "  Cloning https://github.com/hyperkite/hyperkite.git to /tmp/pip-req-build-fd_qhj5y\n",
      "  Running command git clone -q https://github.com/hyperkite/hyperkite.git /tmp/pip-req-build-fd_qhj5y\n",
      "Requirement already satisfied (use --upgrade to upgrade): hyperkite==0.1.2 from git+https://github.com/hyperkite/hyperkite.git in /home/tycho/anaconda3/lib/python3.7/site-packages/hyperkite-0.1.2-py3.7.egg\n",
      "Requirement already satisfied: requests in /home/tycho/anaconda3/lib/python3.7/site-packages (from hyperkite==0.1.2) (2.23.0)\n",
      "Requirement already satisfied: vcrpy in /home/tycho/anaconda3/lib/python3.7/site-packages (from hyperkite==0.1.2) (2.1.0)\n",
      "Requirement already satisfied: nose in /home/tycho/anaconda3/lib/python3.7/site-packages (from hyperkite==0.1.2) (1.3.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/tycho/anaconda3/lib/python3.7/site-packages (from requests->hyperkite==0.1.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tycho/anaconda3/lib/python3.7/site-packages (from requests->hyperkite==0.1.2) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/tycho/anaconda3/lib/python3.7/site-packages (from requests->hyperkite==0.1.2) (1.24.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/tycho/anaconda3/lib/python3.7/site-packages (from requests->hyperkite==0.1.2) (2.8)\n",
      "Requirement already satisfied: wrapt in /home/tycho/anaconda3/lib/python3.7/site-packages (from vcrpy->hyperkite==0.1.2) (1.11.1)\n",
      "Requirement already satisfied: PyYAML in /home/tycho/anaconda3/lib/python3.7/site-packages (from vcrpy->hyperkite==0.1.2) (5.1)\n",
      "Requirement already satisfied: yarl; python_version >= \"3.5\" in /home/tycho/anaconda3/lib/python3.7/site-packages (from vcrpy->hyperkite==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tycho/anaconda3/lib/python3.7/site-packages (from vcrpy->hyperkite==0.1.2) (1.12.0)\n",
      "Requirement already satisfied: multidict>=4.0 in /home/tycho/anaconda3/lib/python3.7/site-packages (from yarl; python_version >= \"3.5\"->vcrpy->hyperkite==0.1.2) (4.5.2)\n",
      "Building wheels for collected packages: hyperkite\n",
      "  Building wheel for hyperkite (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hyperkite: filename=hyperkite-0.1.2-py3-none-any.whl size=3846 sha256=96778ca6875660fedd1f785a51e5787e0c389432a5f1db511f005506ed165e0d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-m9kui02f/wheels/da/85/30/a8b2297d5c3422b5a7de91ce4baf21173ec0fca0d35b4f9cfd\n",
      "Successfully built hyperkite\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/hyperkite/hyperkite.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyperparameter space\n",
    "\n",
    "\n",
    "Sign in to [Hyperkite](https://hyperkite.ai/), and press the 'Create Study' button.\n",
    "\n",
    "<img src=\"https://github.com/hyperkite/Hyperbase/raw/master/hyperkite/docs/source/_static/screenshot_a.PNG\" width=\"50%\"></img>\n",
    "\n",
    "A nice looking interface will allow you to define the hyperparameters you wish to optimize. In our case, let's call our study `tutorial_study`, and select a Uniform Range between `10` and `1000` named `n_layers`. We can use the default `Hyperopt` optimizer. Your screen should look like this:\n",
    "\n",
    "<img src=\"https://github.com/hyperkite/Hyperbase/raw/master/hyperkite/docs/source/_static/screenshot_b.PNG\" width=\"50%\"></img>\n",
    "\n",
    "After defining the hyperparameters you want to optimize in your Study, you will obtain an unique Study `key`. In the next part of the tutorial, this key will be used to easily link our Python training code with Hyperkite.\n",
    "\n",
    "<img src=\"https://github.com/hyperkite/Hyperbase/raw/master/hyperkite/docs/source/_static/screenshot_c.PNG\" width=\"50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Dataset\n",
    "We obtain a collection of handwritten digits by loading the [Digit Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html) from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a ```training```, ```validation``` and ```testing``` subsets.\n",
    "\n",
    "| Split      | # Samples | Description |\n",
    "|------------|-----------|-------------|\n",
    "| Training   | 1400      | The largest portion of the data samples are used to directly train the model. |\n",
    "| Validation | 100       | A small portion the data is withheld to evaluate different hyperparameters.\n",
    "| Testing    | 297       | Another small portion of the data is witheld to evaluate the final performance. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 1400\n",
      "Validation size: 100\n",
      "Testing size: 297\n"
     ]
    }
   ],
   "source": [
    "# Use the first 1400 digits for training\n",
    "train_data = digits.data[:1400]\n",
    "train_labels = digits.target[:1400]\n",
    "\n",
    "# Use the next 150 digits for validation\n",
    "val_data = digits.data[1400:1500]\n",
    "val_labels = digits.target[1400:1500]\n",
    "\n",
    "# Use the last (247) digits for testing\n",
    "test_data = digits.data[1500:]\n",
    "test_labels = digits.target[1500:]\n",
    "\n",
    "print('Training size:', len(train_data))\n",
    "print('Validation size:', len(val_data))\n",
    "print('Testing size:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(i)\n",
    "    plt.imshow(train_data[np.where(train_labels == i)[0][0]].reshape(8, 8), cmap='gray')\n",
    "plt.savefig('dataset_example.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use the ```MLPClassifier``` neural network classifier from ```sklearn``` to fit our data. If you want, you can replace the model with a more advanced neural network using tools such as Keras, PyTorch or Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperkite\n",
    "study_key = '5e837a9666b14316d5c98a94'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6667/10000 [09:39<07:10,  7.74it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "for _ in tqdm(range(10000)):\n",
    "    # Retrive new hyperparameter values from Hyperkite\n",
    "    trial = hyperkite.new_trial(study_key)\n",
    "\n",
    "    values = trial.values\n",
    "    \n",
    "    # Initialize model using received hyper-parameter values\n",
    "    algorithm = ['ball_tree', 'kd_tree', 'brute'][values['algorithm']]\n",
    "    leaf_size = int(values['leaf_size'])\n",
    "    n_neighbors = int(values['n_neighbors'])\n",
    "\n",
    "    model = KNeighborsClassifier(algorithm=algorithm,\n",
    "                                 leaf_size=leaf_size,\n",
    "                                 n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(train_data, train_labels)\n",
    "    \n",
    "    # Report back validation loss\n",
    "    val_loss = log_loss(val_labels, model.predict_proba(val_data))\n",
    "    trial.report_loss(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final performance with Hyperkite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best values:  {'algorithm': 1, 'leaf_size': 513.0, 'n_neighbors': 5.0}\n",
      "Final accuracy without Hyperkite: 0.9562289562289562\n",
      "Final accuracy with Hyperkite: 0.936026936026936\n"
     ]
    }
   ],
   "source": [
    "best_values = hyperkite.get_best_values(study_key)\n",
    "print('Best values: ', best_values)\n",
    "\n",
    "# Set-up best found settings\n",
    "algorithm = ['ball_tree', 'kd_tree', 'brute'][values['algorithm']]\n",
    "leaf_size = int(values['leaf_size'])\n",
    "n_neighbors = int(values['n_neighbors'])\n",
    "\n",
    "normal_model = KNeighborsClassifier()\n",
    "\n",
    "tuned_model = KNeighborsClassifier(algorithm=algorithm,\n",
    "                                   leaf_size=leaf_size,\n",
    "                                   n_neighbors=n_neighbors)\n",
    "\n",
    "# Train model\n",
    "normal_model.fit(train_data, train_labels)\n",
    "tuned_model.fit(train_data, train_labels)\n",
    "\n",
    "\n",
    "# Evaluate final performance of normal model on test set\n",
    "normal_predictions = normal_model.predict(test_data)\n",
    "normal_accuracy = sum(normal_predictions == test_labels) / len(test_labels)\n",
    "print('Final accuracy without Hyperkite:', normal_accuracy)\n",
    "\n",
    "# Evaluate final performance of tuned model on test set\n",
    "tuned_predictions = tuned_model.predict(test_data)\n",
    "tuned_accuracy = sum(tuned_predictions == test_labels) / len(test_labels)\n",
    "print('Final accuracy with Hyperkite:', tuned_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! The model performs a lot better than without hyperparameter tuning. Also note that using our study `key` we can request the best parameter values from hyperkite at any time later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "Well, now that you have learned how to tune hyperparameters with Hyperkite you can start applying this skill on other machine learning models. Try to replace the MultiLayerPerceptron in the tutorial with other models from sklearn, or start training more advanced deep learning models using [TensorFlow](https://www.tensorflow.org/tutorials) and [PyTorch](https://pytorch.org/tutorials/) and try to optimize them with [Hyperkite](https://hyperkite.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
