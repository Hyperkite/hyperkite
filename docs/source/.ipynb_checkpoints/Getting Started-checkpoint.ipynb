{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Hyperkite\n",
    "\n",
    "This short introduction uses Hyperkite to:\n",
    "\n",
    "1. Build a neural network that classifies images.\n",
    "\n",
    "2. Train the model and optimize hyperparameters.\n",
    "\n",
    "3. And finally evaluate the accuracy of the model.\n",
    "\n",
    "This tutorial is part of the original [Hyperkite Documentation](https://hyperkite.ai/docs/getting-started/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the Hyperkite package by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperkite/hyperkite.git\n",
      "  Cloning https://github.com/hyperkite/hyperkite.git to c:\\users\\tycho\\appdata\\local\\temp\\pip-req-build-muroroht\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/hyperkite/hyperkite.git 'C:\\Users\\Tycho\\AppData\\Local\\Temp\\pip-req-build-muroroht'\n",
      "    ERROR: Complete output from command python setup.py egg_info:\n",
      "    ERROR: Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Tycho\\AppData\\Local\\Temp\\pip-req-build-muroroht\\setup.py\", line 3, in <module>\n",
      "        with open(\"README.md\", \"r\") as fh:\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'README.md'\n",
      "    ----------------------------------------\n",
      "ERROR: Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Tycho\\AppData\\Local\\Temp\\pip-req-build-muroroht\\\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/hyperkite/hyperkite.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyperparameter space\n",
    "\n",
    "\n",
    "Sign in to [Hyperkite](https://hyperkite.ai/), and press the 'Create Study' button.\n",
    "\n",
    "<img src=\"https://github.com/hyperkite/Hyperbase/raw/master/hyperkite/docs/source/_static/screenshot_a.PNG\" width=\"50%\"></img>\n",
    "\n",
    "A nice looking interface will allow you to define the hyperparameters you wish to optimize. In our case, let's call our study `tutorial_study`, and select a Uniform Range between `10` and `1000` named `n_layers`. We can use the default `Hyperopt` optimizer. Your screen should look like this:\n",
    "\n",
    "<img src=\"https://github.com/hyperkite/Hyperbase/raw/master/hyperkite/docs/source/_static/screenshot_b.PNG\" width=\"50%\"></img>\n",
    "\n",
    "After defining the hyperparameters you want to optimize in your Study, you will obtain an unique Study `key`. In the next part of the tutorial, this key will be used to easily link our Python training code with Hyperkite.\n",
    "\n",
    "<img src=\"https://github.com/hyperkite/Hyperbase/raw/master/hyperkite/docs/source/_static/screenshot_c.PNG\" width=\"50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Dataset\n",
    "We obtain a collection of handwritten digits by loading the [Digit Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html) from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a ```training```, ```validation``` and ```testing``` subsets.\n",
    "\n",
    "| Split      | # Samples | Description |\n",
    "|------------|-----------|-------------|\n",
    "| Training   | 1400      | The largest portion of the data samples are used to directly train the model. |\n",
    "| Validation | 150       | A small portion the data is withheld to evaluate different hyperparameters.\n",
    "| Testing    | 247       | Another small portion of the data is witheld to evaluate the final performance. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 1400\n",
      "Validation size: 150\n",
      "Testing size: 147\n"
     ]
    }
   ],
   "source": [
    "# Use the first 1400 digits for training\n",
    "train_data = digits.data[:1400]\n",
    "train_labels = digits.target[:1400]\n",
    "\n",
    "# Use the next 150 digits for validation\n",
    "val_data = digits.data[1500:1650]\n",
    "val_labels = digits.target[1500:1650]\n",
    "\n",
    "# Use the last (247) digits for testing\n",
    "test_data = digits.data[1650:]\n",
    "test_labels = digits.target[1650:]\n",
    "\n",
    "print('Training size:', len(train_data))\n",
    "print('Validation size:', len(val_data))\n",
    "print('Testing size:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(i)\n",
    "    plt.imshow(train_data[np.where(train_labels == i)[0][0]].reshape(8, 8), cmap='gray')\n",
    "plt.savefig('dataset_example.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use the ```MLPClassifier``` neural network classifier from ```sklearn``` to fit our data. If you want, you can replace the model with a more advanced neural network using tools such as Keras, PyTorch or Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Wrong response\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9fc600b78580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Initialize model using received hyper-parameter values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import hyperkite\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "for _ in range(100):\n",
    "    # Retrive new hyperparameter values from Hyperkite\n",
    "    trial = hyperkite.new_trial(key='5e8324c866b14316d5c98197')\n",
    "\n",
    "    values = trial.values\n",
    "    \n",
    "    # Initialize model using received hyper-parameter values\n",
    "    activations = ['identity', 'logistic', 'tanh', 'relu'][values['activation_function']]\n",
    "    hidden_layer_sizes = (int(values['hidden_layer_size']))\n",
    "    alpha = values['alpha']\n",
    "    learning_rate_init = values['learning_rate']\n",
    "    \n",
    "    model = MLPClassifier(activation=activation,\n",
    "                          hidden_layer_sizes=hidden_layer_sizes,\n",
    "                          alpha=alpha,\n",
    "                          learning_rate_init=learning_rate_init)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(train_data, train_labels)\n",
    "    \n",
    "    # Report back validation loss\n",
    "    val_loss = log_loss(val_labels, model.predict_proba(val_data))\n",
    "    hyperkite.report_loss(val_loss)\n",
    "    \n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = sum(val_predictions == val_labels) / len(val_labels)\n",
    "print('Validation accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final performance with Hyperkite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperkite.get_best_parameters(key='')\n",
    "\n",
    "# Set-up best found settings\n",
    "model = MLPClassifier(alpha=trial['alpha'],\n",
    "                      learning_rate_init=trial['learnig_rate'])\n",
    "\n",
    "# Train model\n",
    "model.fit(train_data, train_labels)\n",
    "\n",
    "# Evaluate final performance on test set\n",
    "predictions = model.predict(test_data)\n",
    "accuracy = sum(predictions == test_labels) / len(test_labels)\n",
    "print('Final accuracy with Hyperkite:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! The model performs a lot better than without hyperparameter tuning. Also note that using our study `key` we can request the best parameter values from hyperkite at any time later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "Well, now that you have learned how to tune hyperparameters with Hyperkite you can start applying this skill on other machine learning models. Try to replace the MultiLayerPerceptron in the tutorial with other models from sklearn, or start training more advanced deep learning models using [TensorFlow](https://www.tensorflow.org/tutorials) and [PyTorch](https://pytorch.org/tutorials/) and try to optimize them with [Hyperkite](https://hyperkite.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
